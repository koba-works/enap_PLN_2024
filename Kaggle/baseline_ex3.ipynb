{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7b9812-db7c-46a3-aeb4-8b32c1df4b9b",
   "metadata": {},
   "source": [
    "# Reconhecimento de Entidades Nomeadas usando LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c34ad04-1e63-4a9f-bda0-434ed288b953",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5b7c8f-367c-4f9d-8171-d574cd47be91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca148778-39a6-40ff-9e75-803d0b82f67d",
   "metadata": {},
   "source": [
    "## Carregando os datasets de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a9621d5-5e3e-45c9-9b37-a7d8f0e61c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bccb1c1-bc24-4b16-8719-9a9f2e512f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"conll2003\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "148090c4-8a96-4c61-9349-ff2355991a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = train_dataset['tokens']\n",
    "ner_tags = train_dataset['ner_tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e5f0e6-802a-4d98-a5a0-2b0f074717d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb6201d-f20e-4818-ab1b-724c6a94c579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>ner_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[EU, rejects, German, call, to, boycott, Briti...</td>\n",
       "      <td>[3, 0, 7, 0, 0, 0, 7, 0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Peter, Blackburn]</td>\n",
       "      <td>[1, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[BRUSSELS, 1996-08-22]</td>\n",
       "      <td>[5, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[The, European, Commission, said, on, Thursday...</td>\n",
       "      <td>[0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Germany, 's, representative, to, the, Europea...</td>\n",
       "      <td>[5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [EU, rejects, German, call, to, boycott, Briti...   \n",
       "1                                 [Peter, Blackburn]   \n",
       "2                             [BRUSSELS, 1996-08-22]   \n",
       "3  [The, European, Commission, said, on, Thursday...   \n",
       "4  [Germany, 's, representative, to, the, Europea...   \n",
       "\n",
       "                                            ner_tags  \n",
       "0                        [3, 0, 7, 0, 0, 0, 7, 0, 0]  \n",
       "1                                             [1, 2]  \n",
       "2                                             [5, 0]  \n",
       "3  [0, 3, 4, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, ...  \n",
       "4  [5, 0, 0, 0, 0, 3, 4, 0, 0, 0, 1, 2, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['tokens','ner_tags']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d86eb8b-25b7-4c2e-9f62-4f46b262c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "int2tag = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "441e16f7-26e7-40a6-aa20-c08cd7773c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2int = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94f149cb-d929-48e8-aff7-9c0a398f7a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag2tensor = {'O':      [1,0,0,0,0,0,0,0,0],\n",
    "              'B-PER':  [0,1,0,0,0,0,0,0,0], \n",
    "              'I-PER':  [0,0,1,0,0,0,0,0,0], \n",
    "              'B-ORG':  [0,0,0,1,0,0,0,0,0], \n",
    "              'I-ORG':  [0,0,0,0,1,0,0,0,0], \n",
    "              'B-LOC':  [0,0,0,0,0,1,0,0,0], \n",
    "              'I-LOC':  [0,0,0,0,0,0,1,0,0], \n",
    "              'B-MISC': [0,0,0,0,0,0,0,1,0], \n",
    "              'I-MISC': [0,0,0,0,0,0,0,0,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d0b4eda-d14a-44bc-8a54-65018ea28cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: EU | text label: B-ORG | one-hot label [0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "Word: rejects | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: German | text label: B-MISC | one-hot label [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Word: call | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: to | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: boycott | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: British | text label: B-MISC | one-hot label [0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
      "Word: lamb | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Word: . | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "words = train_dataset['tokens']\n",
    "ner_tags = train_dataset['ner_tags']\n",
    "\n",
    "for i in range(0,len(words[0])):\n",
    "    print(f'Word: {words[0][i]} | text label: {int2tag[ner_tags[0][i]]} | one-hot label {tag2tensor[int2tag[ner_tags[0][i]]]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc854e56-1f74-418f-b15c-2b055752cc46",
   "metadata": {},
   "source": [
    "## Usando word2vec para os embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0079deed-73c0-43e7-a975-0fb4e93de0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e07ee48-b9fc-4780-92d7-880a9e24c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = api.load(\"word2vec-google-news-300\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f61fdff-08d0-4d82-9ca0-b4bd63a5ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens2vec(tokens):\n",
    "    vectors = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            vector = word2vec[token]\n",
    "            vectors.append(vector)\n",
    "        except KeyError:\n",
    "            vectors.append(np.zeros(word2vec.vector_size))\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6dfa32-8630-4a09-9f5f-1378235eda30",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vectors = [tokens2vec(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa9bf94b-695f-4011-948b-62ae1b8b495a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: EU | text label: B-ORG | one-hot label [0, 0, 0, 1, 0, 0, 0, 0, 0] | word2vec [ 0.03735352 -0.203125    0.21289062]\n",
      "Word: rejects | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [0.00982666 0.2265625  0.28125   ]\n",
      "Word: German | text label: B-MISC | one-hot label [0, 0, 0, 0, 0, 0, 0, 1, 0] | word2vec [0.30664062 0.11035156 0.16699219]\n",
      "Word: call | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [-0.11816406  0.08154297  0.15039062]\n",
      "Word: to | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [0. 0. 0.]\n",
      "Word: boycott | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [-0.04272461  0.08203125  0.12207031]\n",
      "Word: British | text label: B-MISC | one-hot label [0, 0, 0, 0, 0, 0, 0, 1, 0] | word2vec [-0.06542969 -0.02038574  0.01452637]\n",
      "Word: lamb | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [-0.08007812  0.15625    -0.35351562]\n",
      "Word: . | text label: O | one-hot label [1, 0, 0, 0, 0, 0, 0, 0, 0] | word2vec [0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(words[0])):\n",
    "    print(f'Word: {words[0][i]} | text label: {int2tag[ner_tags[0][i]]} | one-hot label {tag2tensor[int2tag[ner_tags[0][i]]]} | word2vec {words_vectors[0][i][:3]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b88e640-8e51-4420-8fea-9a443508a444",
   "metadata": {},
   "source": [
    "## Criando o DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c12e6fd-9600-42d0-bf54-58bbe9d22bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca6b365-0953-4066-bffd-f8893758e242",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = [], []\n",
    "for vectors, tags in zip(words_vectors, ner_tags):\n",
    "    for vec, tag in zip(vectors, tags):\n",
    "        X_train.append(torch.tensor(vec,  dtype=torch.float32))\n",
    "        y_train.append(torch.tensor(tag2tensor[int2tag[tag]],  dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34357eea-33f6-4209-b45c-71bc39af1a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.stack(X_train), torch.stack(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d18fece3-a4b3-4bc1-8d7d-2fb5eddd89b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0058e0ba-19bf-47de-821c-69e8986acd12",
   "metadata": {},
   "source": [
    "## Classe da rede LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "20973ac2-05c4-447e-89ad-ae6a8e67f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "221e96d7-fa53-4cd8-9660-d24c85b17456",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  \n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_hidden_state = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_hidden_state)        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72f91a-db30-4bb6-b99b-7f94ddaf51ab",
   "metadata": {},
   "source": [
    "## Instanciando a rede LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26307d01-348c-447e-bd69-7b4e892e424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=300, hidden_size=128, output_size=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e06aa7f1-be92-48a0-a649-21baacaecacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05098e-e1ea-43a9-9b91-5646a0a4f935",
   "metadata": {},
   "source": [
    "## Treinando a rede LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ce555b3-5907-4210-b8cb-2cd128736d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lpfgarcia/miniconda3/envs/enap/lib/python3.11/site-packages/torch/autograd/__init__.py:266: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.2506\n",
      "Epoch [2/10], Loss: 0.1929\n",
      "Epoch [3/10], Loss: 0.1764\n",
      "Epoch [4/10], Loss: 0.1657\n",
      "Epoch [5/10], Loss: 0.1582\n",
      "Epoch [6/10], Loss: 0.1527\n",
      "Epoch [7/10], Loss: 0.1484\n",
      "Epoch [8/10], Loss: 0.1455\n",
      "Epoch [9/10], Loss: 0.1429\n",
      "Epoch [10/10], Loss: 0.1408\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(data_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0e14683a-50a9-4df9-89c0-154951ee1644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (lstm): LSTM(300, 128)\n",
       "  (fc): Linear(in_features=128, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51de7767-1ec3-45bb-934c-c5959a1914b4",
   "metadata": {},
   "source": [
    "## Testando a rede LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57b9b682-1026-427f-9eb5-6711514998b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc988ec7-c13c-4a44-8bba-9fce65108939",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2fa3598c-484c-4a59-8d13-9936b685e834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2619</td>\n",
       "      <td>['(', '52.76', '/', '53.18', ')']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456</td>\n",
       "      <td>['WESTERN', 'CONFERENCE']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>102</td>\n",
       "      <td>['Wasim', 'Akram', 'b', 'Harris', '4']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3037</td>\n",
       "      <td>['Mansfield', '21', '5', '9', '7', '21', '22',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1126</td>\n",
       "      <td>['--', 'New', 'York', 'Commodities', 'Desk', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                             tokens\n",
       "0  2619                  ['(', '52.76', '/', '53.18', ')']\n",
       "1   456                          ['WESTERN', 'CONFERENCE']\n",
       "2   102             ['Wasim', 'Akram', 'b', 'Harris', '4']\n",
       "3  3037  ['Mansfield', '21', '5', '9', '7', '21', '22',...\n",
       "4  1126  ['--', 'New', 'York', 'Commodities', 'Desk', '..."
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "723f8816-d212-429d-8b07-c4f17e1ceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Dataset.from_pandas(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dc01d8a4-5aac-4ade-9c6e-848a30b44cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = test_dataset['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f8b8797-5885-414b-a4e5-85c1a394ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [eval(text) for text in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9798b8b-598f-4439-9450-69b69bd9935b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(', '52.76', '/', '53.18', ')']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b8d9820-781b-4d03-ae39-3c11b973d577",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vectors = [tokens2vec(word) for word in words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcf1c753-5012-4efc-9813-0387e10f6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "for vectors in words_vectors:\n",
    "    for vec in vectors:\n",
    "        X_test.append(torch.tensor(vec,  dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73aa7c3a-8962-404e-9167-afabd350f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(torch.stack(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae237aaf-c565-48dd-b3a1-ea1bece6d14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a80e00da-e5e0-4768-b2a9-33c2e23a098f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = []\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        outputs = model(*inputs)\n",
    "        _, predicted = torch.max(outputs, 1) \n",
    "        predicted_list.extend(predicted.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42ce72b7-0471-4b88-9332-c13ad6f0ec16",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_list = np.array(predicted_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c8422ef5-ee1b-46f6-9941-8285ef13ed20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 5, 0, 5, 2, 3, 0, 0, 0, 0, 0, 5, 0, 3,\n",
       "       3, 2, 0, 3, 0, 0, 6, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0,\n",
       "       0, 0, 2, 4, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 3,\n",
       "       8, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 5, 0, 3, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_list[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "07443711-cf57-473b-be3a-ff26a108ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for word in words:\n",
    "    aux = len(word)\n",
    "    y_pred.append(predicted_list[:aux])\n",
    "    predicted_list = predicted_list[aux:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1837ba2-c152-4b0b-9f22-a1f6c3e09a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = [array.tolist() for array in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b123811f-c60a-4ede-b33b-45844f1ee623",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pd.DataFrame({'ner_tags': y_pred}, index=test.ID) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "14754a8b-a03f-46a4-81e4-4c6bc8cb8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.to_csv('ner-solution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d83b11-0ebb-4604-b535-a514752dc418",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
